{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.csdn.net/qq_14845119/article/details/79028094\n",
    "## 原文：https://blog.csdn.net/ali197294332/article/details/78720309 \n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "## 对于灰度图，PIL读出是二维的矩阵\n",
    "#from PIL import Image\n",
    "## cv对任何图像都会按照RGB的方式读取\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tf.python_io.TFRecordWriter返回一个writer对象用于将data_dir制作后的数据存入filepath中保存，\n",
    "该文件就是tfrecords文件。另外，tf.train.Example将数据处理成key-value(在这里就是标签-图像)的\n",
    "格式返回一个example对象。最后writer将数据写到filepath中，关闭writer，\n",
    "就完成了图片数据到二进制文件的制作过程。\n",
    "'''\n",
    "\n",
    "data_path = 'datasets/Mnist/'\n",
    "train_tfrecords_dir = 'datasets/Mnist/train.tfrecords'\n",
    "test_tfrecords_dir = 'datasets/Mnist/test.tfrecords'\n",
    "num_classes = [str(i) for i in range(0,10)]\n",
    "\n",
    "\n",
    "# data to int64List\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list = tf.train.Int64List(value=[value]))\n",
    "# data to floatlist\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value=[value]))\n",
    "# data to byteslist\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "# convert image data to tfrecords\n",
    "def generate_tfrecords(data_dir, filepath):\n",
    "    # gen a tfrecords object writer\n",
    "    writer = tf.python_io.TFRecordWriter(filepath)\n",
    "    \n",
    "    for index, name in enumerate(num_classes):\n",
    "        file_dir = data_dir + name + '/'\n",
    "        for img_name in os.listdir(file_dir):\n",
    "            img_path = file_dir + img_name\n",
    "            img = cv2.imread(img_path)\n",
    "            img_raw = img.tobytes()\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'label': _int64_feature(index),\n",
    "                'img_raw': _bytes_feature(img_raw)\n",
    "            }))\n",
    "            # covert example to binary string\n",
    "            # for every image!!\n",
    "            writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "def generate_data():\n",
    "    train_data_path = data_path + 'mnist_train/'\n",
    "    test_data_path = data_path + 'mnist_test/'\n",
    "    \n",
    "    generate_tfrecords(train_data_path, train_tfrecords_dir)\n",
    "    generate_tfrecords(test_data_path, test_tfrecords_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "制作完成之后，在神经网络中如何读取和解析呢？如下代码\n",
    "其中，tf.train.string_input_producer([filename])是将filename的文件内容制作成一个队列，\n",
    "然后tf.parse_single_example按照固定的格式将内容解析出来，稍加处理即可得到label和img，\n",
    "当然[filename]中可以有很多file，因为当图片数据太大时可能会将数据分成好几个部分\n",
    "分别制作tfrecords进行存储和读取。\n",
    "'''\n",
    "def read_and_decode_tfrecored(filename):\n",
    "    # produce file queue\n",
    "    filename_dequeue = tf.train.string_input_producer([filename])\n",
    "        \n",
    "    # gen readere object\n",
    "    reader = tf.TFRecordReader()\n",
    "    # read data from filename_queue\n",
    "    _, serialized_example = reader.read(filename_dequeue)\n",
    "        \n",
    "    # decode\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                        features={\n",
    "                                            'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                            'img_raw': tf.FixedLenFeature([], tf.string)\n",
    "                                        })\n",
    "    \n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "    img = tf.reshape(img,[28,28,3])\n",
    "    img = tf.cast(img,tf.float32)/255. - 0.5\n",
    "        \n",
    "    return label, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tf.contrib.layers.xavier_initializer_conv2d()是对参数进行初始化的，\n",
    "据某位童鞋的博客说，当激活函数是sigmoid或tanh时，这个初始化方法比较好，\n",
    "但是当激活函数是relu时，使用tf.contrib.layers.variance_scaling_initializer比较好，\n",
    "另外tf.contrib.layers.xavier_initializer()也是一种权值初始化方式。\n",
    "而在神经网络中，权值的初始化非常重要，可以按照某种特定的分布来初始化，\n",
    "以后可以尝试使用其他初始化方式从而加快收敛速度和准确率。\n",
    "'''\n",
    "\n",
    "# set parameter\n",
    "epoch = 10000 # step\n",
    "batch_size = 2000 # 100\n",
    "\n",
    "\n",
    "## create network\n",
    "\n",
    "class network(object):\n",
    "    # define parameters w and b\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('weight'):\n",
    "            self.weights = {\n",
    "                'conv1': tf.get_variable('conv1', [5,5,3,32], \n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "                'conv2': tf.get_variable('conv2', [5,5,32,64], \n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "                'fc1': tf.get_variable('fc1', [7*7*64,1024], \n",
    "                                         initializer=tf.contrib.layers.xavier_initializer()),\n",
    "                'fc2': tf.get_variable('fc2', [1024,10], \n",
    "                                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "            }\n",
    "        with tf.variable_scope('bias'):\n",
    "            self.biases = {\n",
    "                'conv1': tf.get_variable('conv1', [32,],\n",
    "                                         initializer=tf.constant_initializer(value=0.0, dtype=tf.float32)),\n",
    "                'conv2': tf.get_variable('conv2', [64,],\n",
    "                                         initializer=tf.constant_initializer(value=0.0, dtype=tf.float32)),\n",
    "                'fc1': tf.get_variable('fc1', [1024,],\n",
    "                                         initializer=tf.constant_initializer(value=0.0, dtype=tf.float32)),\n",
    "                'fc2': tf.get_variable('fc2', [10,],\n",
    "                                         initializer=tf.constant_initializer(value=0.0, dtype=tf.float32))\n",
    "            }\n",
    "    \n",
    "    # define model\n",
    "    def model(self,img):\n",
    "        conv1 = tf.nn.bias_add(tf.nn.conv2d(img, self.weights['conv1'], strides=[1,1,1,1], padding='SAME'),\n",
    "                              self.biases['conv1'])\n",
    "        relu1 = tf.nn.relu(conv1)\n",
    "        pool1 = tf.nn.max_pool(relu1, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        conv2 = tf.nn.bias_add(tf.nn.conv2d(pool1, self.weights['conv2'], strides=[1,1,1,1], padding='SAME'),\n",
    "                              self.biases['conv2'])\n",
    "        relu2 = tf.nn.relu(conv2)\n",
    "        pool2 = tf.nn.max_pool(relu2, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        flatten = tf.reshape(pool2, [-1, self.weights['fc1'].get_shape().as_list()[0]])\n",
    "        \n",
    "        drop1 = tf.nn.dropout(flatten, 0.8)\n",
    "        \n",
    "        fc1 = tf.matmul(drop1, self.weights['fc1']) + self.biases['fc1']\n",
    "        fc1_relu = tf.nn.relu(fc1)\n",
    "        \n",
    "        fc2 = tf.matmul(fc1_relu, self.weights['fc2']) + self.biases['fc2']\n",
    "        \n",
    "        return fc2\n",
    "    \n",
    "    # define model test\n",
    "    def test(self, img):\n",
    "        img = tf.reshape(img, shape=[-1,28,28,3])\n",
    "        \n",
    "        conv1 = tf.nn.bias_add(tf.nn.conv2d(img, self.weights['conv1'], strides=[1,1,1,1], padding='SAME'),\n",
    "                              self.biases['conv1'])\n",
    "        relu1 = tf.nn.relu(conv1)\n",
    "        pool1 = tf.nn.max_pool(relu1, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        conv2 = tf.nn.bias_add(tf.nn.conv2d(pool1, self.weights['conv2'], strides=[1,1,1,1], padding='SAME'),\n",
    "                              self.biases['conv2'])\n",
    "        relu2 = tf.nn.relu(conv2)\n",
    "        pool2 = tf.nn.max_pool(relu2, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        flatten = tf.reshape(pool2, [-1, self.weights['fc1'].get_shape().as_list()[0]])\n",
    "        \n",
    "        drop1 = tf.nn.dropout(flatten, 1)\n",
    "        \n",
    "        fc1 = tf.matmul(drop1, self.weights['fc1']) + self.biases['fc1']\n",
    "        fc1_relu = tf.nn.relu(fc1)\n",
    "        \n",
    "        fc2 = tf.matmul(fc1_relu, self.weights['fc2']) + self.biases['fc2']\n",
    "        \n",
    "        return fc2\n",
    "    \n",
    "    # loss\n",
    "    def softmax_loss(self, predicts, labels):\n",
    "        predicts = tf.nn.softmax(predicts)\n",
    "        labels = tf.one_hot(labels, len(num_classes))\n",
    "        loss = -tf.reduce_mean(labels*tf.log(predicts))\n",
    "        \n",
    "        self.cost = loss\n",
    "        \n",
    "        return self.cost\n",
    "    \n",
    "    # optimizer\n",
    "    def optimizer(self, loss, lr=0.001):\n",
    "        train_op = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "        \n",
    "        return train_op\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " tf.train.shuffle_batch是将队列里的数据打乱顺序使用n_threads个线程，\n",
    " batch_size大小的形式读取出来，capacity是整个队列的容量，min_after_deque代表参与顺序打乱的程度，\n",
    " 参数越大代表数据越混乱。在本代码中，由于各个类别已经分好，大概都是5000张，而在制作tfrecords的时候是按顺序存储的，\n",
    " 所以使用tf.train.shuffle_batch来打乱顺序，但是如果batch_size设置太小，\n",
    " 那很大概率上每个batch_size的图像数据的类别都是一样的，造成过拟合，所以本次将batch_size设置成2000，\n",
    " 这样效果比较明显，设置成1000也可以，或者在处理数据的时候提前将数据打乱，或者有其他方法欢迎下方讨论。\n",
    " \n",
    " 队列容量是50000,使用16个线程同步往一个队列中塞，塞满为止;\n",
    "'''\n",
    "\n",
    "def train():\n",
    "    label, img = read_and_decode_tfrecored(train_tfrecords_dir)\n",
    "    img_batch, label_batch = tf.train.shuffle_batch([img,label], \n",
    "                                             num_threads=16, batch_size=batch_size,\n",
    "                                             capacity = 50000, min_after_dequeue=49000)\n",
    "    net = network()\n",
    "    predicts = net.model(img_batch)\n",
    "    loss = net.softmax_loss(predicts, label_batch)\n",
    "    opti = net.optimizer(loss)\n",
    "    \n",
    "    # add trace\n",
    "    tf.summary.scalar('cost_function', loss)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    ## label_batch must be ont-hot array!!\n",
    "    train_correct = tf.equal(tf.cast(tf.argmax(predicts, 1), tf.int32), label_batch)\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(train_correct, tf.float32))\n",
    "    \n",
    "    # evaluate\n",
    "    test_label, test_img = read_and_decode_tfrecored(test_tfrecords_dir)\n",
    "    test_img_batch, test_label_batch = tf.train.shuffle_batch([test_img, test_label],\n",
    "                                                             num_threads=16, batch_size=batch_size,\n",
    "                                                             capacity=50000, min_after_dequeue=40000)\n",
    "    test_out = net.test(test_img_batch)\n",
    "    test_correct = tf.equal(tf.cast(tf.argmax(test_out,1), tf.int32), test_label_batch)\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(test_correct, tf.float32))\n",
    "    \n",
    "    \n",
    "    # init variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        # manage different threads\n",
    "        coord = tf.train.Coordinator() # #创建一个协调器，用于管理线程，发生错误时及时关闭线程\n",
    "        summary_writer = tf.summary.FileWriter('log', sess.graph)\n",
    "        \n",
    "        # run deque\n",
    "        # #各个线程开始读取数据，这一句如果没有，整个网络将被挂起\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        model_path = data_path + 'model.ckpt'\n",
    "        \n",
    "        # 模型恢复\n",
    "        try:\n",
    "            print(\"try to reload model...\")\n",
    "            tf.train.Saver(max_to_keep=None).restore(sess, model_path)\n",
    "            print(\"reload sucessful...\")\n",
    "        except:\n",
    "            print(\"reload model failed...\")\n",
    "        finally:\n",
    "            print(\"training...\")\n",
    "        \n",
    "        for i in range(1, epoch+1):\n",
    "            if i%50 == 0:\n",
    "                loss_np, _, label_np, img_np, predict_np = sess.run(\n",
    "                    [loss, opti, label_batch, img_batch, predicts])\n",
    "                tr_accuracy_np = sess.run([train_accuracy])\n",
    "                print(i, \"epch loss: \", loss_np, \"   train accuracy: \", tr_accuracy_np)\n",
    "                \n",
    "            if i%200 == 0:\n",
    "                summary_str, _l, _o = sess.run([merged_summary_op, loss, opti])\n",
    "                summary_writer.add_summary(summary_str, i)\n",
    "                te_acccracy = sess.run([test_accuracy])\n",
    "                print(\"test accuracy: \", te_acccracy)\n",
    "            \n",
    "            # 模型保存，max_to_keep=None这个参数是保存最新的或者加载最新的模型\n",
    "            if i%1000 == 0:\n",
    "                tf.train.Saver(max_to_keep=None).save(sess, os.path.join(data_path, 'model.ckpt'))\n",
    "        \n",
    "        # 某个线程数据读取完或发生错误请求停止\n",
    "        coord.request_stop()\n",
    "        \n",
    "        # #所有线程都请求停止后关闭线程\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to reload model...\n",
      "INFO:tensorflow:Restoring parameters from datasets/Mnist/model.ckpt\n",
      "reload model failed...\n",
      "training...\n",
      "50 epch loss:  0.23117173    train accuracy:  [0.1095]\n",
      "100 epch loss:  0.23174207    train accuracy:  [0.092]\n",
      "150 epch loss:  0.23199707    train accuracy:  [0.093]\n",
      "200 epch loss:  0.23159732    train accuracy:  [0.093]\n",
      "test accuracy:  [0.1245]\n",
      "250 epch loss:  0.2315979    train accuracy:  [0.0825]\n",
      "300 epch loss:  0.23347627    train accuracy:  [0.0955]\n",
      "350 epch loss:  0.23239844    train accuracy:  [0.095]\n",
      "400 epch loss:  0.23227236    train accuracy:  [0.119]\n",
      "test accuracy:  [0.115]\n",
      "450 epch loss:  0.2294564    train accuracy:  [0.14]\n",
      "500 epch loss:  0.22905229    train accuracy:  [0.152]\n",
      "550 epch loss:  0.22907148    train accuracy:  [0.1285]\n",
      "600 epch loss:  0.23021816    train accuracy:  [0.1305]\n",
      "test accuracy:  [0.121]\n",
      "650 epch loss:  0.23129123    train accuracy:  [0.112]\n",
      "700 epch loss:  0.2315977    train accuracy:  [0.093]\n",
      "750 epch loss:  0.23202363    train accuracy:  [0.1055]\n",
      "800 epch loss:  0.23099466    train accuracy:  [0.0905]\n",
      "test accuracy:  [0.1075]\n",
      "850 epch loss:  0.23448984    train accuracy:  [0.0745]\n",
      "900 epch loss:  0.23191917    train accuracy:  [0.1135]\n",
      "950 epch loss:  0.23189145    train accuracy:  [0.1045]\n",
      "1000 epch loss:  0.2311769    train accuracy:  [0.1495]\n",
      "test accuracy:  [0.1365]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "1050 epch loss:  0.22953145    train accuracy:  [0.1545]\n",
      "1100 epch loss:  0.22869712    train accuracy:  [0.1375]\n",
      "1150 epch loss:  0.23064311    train accuracy:  [0.139]\n",
      "1200 epch loss:  0.23122568    train accuracy:  [0.114]\n",
      "test accuracy:  [0.129]\n",
      "1250 epch loss:  0.23202847    train accuracy:  [0.099]\n",
      "1300 epch loss:  0.23160896    train accuracy:  [0.09]\n",
      "1350 epch loss:  0.23094082    train accuracy:  [0.0965]\n",
      "1400 epch loss:  0.23127204    train accuracy:  [0.0765]\n",
      "test accuracy:  [0.1155]\n",
      "1450 epch loss:  0.23166704    train accuracy:  [0.106]\n",
      "1500 epch loss:  0.23191524    train accuracy:  [0.099]\n",
      "1550 epch loss:  0.2317397    train accuracy:  [0.146]\n",
      "1600 epch loss:  0.22990215    train accuracy:  [0.154]\n",
      "test accuracy:  [0.1255]\n",
      "1650 epch loss:  0.22878572    train accuracy:  [0.145]\n",
      "1700 epch loss:  0.2295912    train accuracy:  [0.128]\n",
      "1750 epch loss:  0.23189287    train accuracy:  [0.114]\n",
      "1800 epch loss:  0.23204492    train accuracy:  [0.1045]\n",
      "test accuracy:  [0.124]\n",
      "1850 epch loss:  0.23248565    train accuracy:  [0.1125]\n",
      "1900 epch loss:  0.23168409    train accuracy:  [0.1005]\n",
      "1950 epch loss:  0.23177929    train accuracy:  [0.095]\n",
      "2000 epch loss:  0.2329216    train accuracy:  [0.105]\n",
      "test accuracy:  [0.1265]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "2050 epch loss:  0.23190916    train accuracy:  [0.09]\n",
      "2100 epch loss:  0.23060103    train accuracy:  [0.1315]\n",
      "2150 epch loss:  0.23019563    train accuracy:  [0.162]\n",
      "2200 epch loss:  0.22866431    train accuracy:  [0.158]\n",
      "test accuracy:  [0.127]\n",
      "2250 epch loss:  0.22987354    train accuracy:  [0.1235]\n",
      "2300 epch loss:  0.23063886    train accuracy:  [0.135]\n",
      "2350 epch loss:  0.2323665    train accuracy:  [0.118]\n",
      "2400 epch loss:  0.23301782    train accuracy:  [0.112]\n",
      "test accuracy:  [0.116]\n",
      "2450 epch loss:  0.2319123    train accuracy:  [0.0895]\n",
      "2500 epch loss:  0.23136167    train accuracy:  [0.0915]\n",
      "2550 epch loss:  0.2330995    train accuracy:  [0.087]\n",
      "2600 epch loss:  0.23212542    train accuracy:  [0.107]\n",
      "test accuracy:  [0.1315]\n",
      "2650 epch loss:  0.23138803    train accuracy:  [0.11]\n",
      "2700 epch loss:  0.23010136    train accuracy:  [0.151]\n",
      "2750 epch loss:  0.22922193    train accuracy:  [0.1385]\n",
      "2800 epch loss:  0.22868393    train accuracy:  [0.143]\n",
      "test accuracy:  [0.1215]\n",
      "2850 epch loss:  0.2297624    train accuracy:  [0.1375]\n",
      "2900 epch loss:  0.23179428    train accuracy:  [0.1155]\n",
      "2950 epch loss:  0.23270689    train accuracy:  [0.1175]\n",
      "3000 epch loss:  0.23197724    train accuracy:  [0.1025]\n",
      "test accuracy:  [0.139]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "3050 epch loss:  0.23080234    train accuracy:  [0.0935]\n",
      "3100 epch loss:  0.23249145    train accuracy:  [0.087]\n",
      "3150 epch loss:  0.23201631    train accuracy:  [0.1055]\n",
      "3200 epch loss:  0.23144895    train accuracy:  [0.1]\n",
      "test accuracy:  [0.1365]\n",
      "3250 epch loss:  0.22978975    train accuracy:  [0.1525]\n",
      "3300 epch loss:  0.22916465    train accuracy:  [0.154]\n",
      "3350 epch loss:  0.22867104    train accuracy:  [0.135]\n",
      "3400 epch loss:  0.22866057    train accuracy:  [0.137]\n",
      "test accuracy:  [0.13]\n",
      "3450 epch loss:  0.23153251    train accuracy:  [0.1155]\n",
      "3500 epch loss:  0.23266953    train accuracy:  [0.111]\n",
      "3550 epch loss:  0.23160227    train accuracy:  [0.0995]\n",
      "3600 epch loss:  0.2312887    train accuracy:  [0.099]\n",
      "test accuracy:  [0.1185]\n",
      "3650 epch loss:  0.23180357    train accuracy:  [0.088]\n",
      "3700 epch loss:  0.23310393    train accuracy:  [0.0975]\n",
      "3750 epch loss:  0.23177569    train accuracy:  [0.1105]\n",
      "3800 epch loss:  0.23126669    train accuracy:  [0.123]\n",
      "test accuracy:  [0.1335]\n",
      "3850 epch loss:  0.2298841    train accuracy:  [0.1455]\n",
      "3900 epch loss:  0.22854179    train accuracy:  [0.147]\n",
      "3950 epch loss:  0.22909985    train accuracy:  [0.1485]\n",
      "4000 epch loss:  0.23037261    train accuracy:  [0.1255]\n",
      "test accuracy:  [0.144]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "4050 epch loss:  0.23154473    train accuracy:  [0.1145]\n",
      "4100 epch loss:  0.23142427    train accuracy:  [0.1015]\n",
      "4150 epch loss:  0.23171811    train accuracy:  [0.1005]\n",
      "4200 epch loss:  0.23015845    train accuracy:  [0.0955]\n",
      "test accuracy:  [0.1345]\n",
      "4250 epch loss:  0.23352107    train accuracy:  [0.0825]\n",
      "4300 epch loss:  0.23133999    train accuracy:  [0.1155]\n",
      "4350 epch loss:  0.2317615    train accuracy:  [0.1145]\n",
      "4400 epch loss:  0.22990288    train accuracy:  [0.1515]\n",
      "test accuracy:  [0.1215]\n",
      "4450 epch loss:  0.22924785    train accuracy:  [0.1565]\n",
      "4500 epch loss:  0.22921114    train accuracy:  [0.143]\n",
      "4550 epch loss:  0.23036343    train accuracy:  [0.14]\n",
      "4600 epch loss:  0.23119594    train accuracy:  [0.1165]\n",
      "test accuracy:  [0.128]\n",
      "4650 epch loss:  0.23188025    train accuracy:  [0.1085]\n",
      "4700 epch loss:  0.23206036    train accuracy:  [0.0955]\n",
      "4750 epch loss:  0.23081641    train accuracy:  [0.1105]\n",
      "4800 epch loss:  0.23186284    train accuracy:  [0.0805]\n",
      "test accuracy:  [0.1305]\n",
      "4850 epch loss:  0.23193687    train accuracy:  [0.121]\n",
      "4900 epch loss:  0.2318521    train accuracy:  [0.102]\n",
      "4950 epch loss:  0.23120064    train accuracy:  [0.153]\n",
      "5000 epch loss:  0.22881587    train accuracy:  [0.158]\n",
      "test accuracy:  [0.142]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "5050 epch loss:  0.2289687    train accuracy:  [0.1455]\n",
      "5100 epch loss:  0.23025294    train accuracy:  [0.115]\n",
      "5150 epch loss:  0.23042612    train accuracy:  [0.1315]\n",
      "5200 epch loss:  0.23139358    train accuracy:  [0.118]\n",
      "test accuracy:  [0.1385]\n",
      "5250 epch loss:  0.23169175    train accuracy:  [0.1185]\n",
      "5300 epch loss:  0.23070152    train accuracy:  [0.105]\n",
      "5350 epch loss:  0.23081826    train accuracy:  [0.0945]\n",
      "5400 epch loss:  0.23336661    train accuracy:  [0.1055]\n",
      "test accuracy:  [0.128]\n",
      "5450 epch loss:  0.23140007    train accuracy:  [0.098]\n",
      "5500 epch loss:  0.23197414    train accuracy:  [0.14]\n",
      "5550 epch loss:  0.22947676    train accuracy:  [0.1495]\n",
      "5600 epch loss:  0.22799483    train accuracy:  [0.1585]\n",
      "test accuracy:  [0.131]\n",
      "5650 epch loss:  0.22885622    train accuracy:  [0.1345]\n",
      "5700 epch loss:  0.23055156    train accuracy:  [0.1265]\n",
      "5750 epch loss:  0.23153345    train accuracy:  [0.118]\n",
      "5800 epch loss:  0.23100391    train accuracy:  [0.1]\n",
      "test accuracy:  [0.128]\n",
      "5850 epch loss:  0.23109016    train accuracy:  [0.0985]\n",
      "5900 epch loss:  0.23058133    train accuracy:  [0.0945]\n",
      "5950 epch loss:  0.23254895    train accuracy:  [0.1005]\n",
      "6000 epch loss:  0.23130761    train accuracy:  [0.1155]\n",
      "test accuracy:  [0.1425]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6050 epch loss:  0.23123375    train accuracy:  [0.1265]\n",
      "6100 epch loss:  0.22934873    train accuracy:  [0.1575]\n",
      "6150 epch loss:  0.2289218    train accuracy:  [0.1645]\n",
      "6200 epch loss:  0.22846186    train accuracy:  [0.1535]\n",
      "test accuracy:  [0.142]\n",
      "6250 epch loss:  0.23023058    train accuracy:  [0.135]\n",
      "6300 epch loss:  0.23086162    train accuracy:  [0.122]\n",
      "6350 epch loss:  0.2314019    train accuracy:  [0.116]\n",
      "6400 epch loss:  0.2310524    train accuracy:  [0.108]\n",
      "test accuracy:  [0.1325]\n",
      "6450 epch loss:  0.23035732    train accuracy:  [0.0875]\n",
      "6500 epch loss:  0.23202056    train accuracy:  [0.097]\n",
      "6550 epch loss:  0.23207876    train accuracy:  [0.128]\n",
      "6600 epch loss:  0.23113728    train accuracy:  [0.0995]\n",
      "test accuracy:  [0.136]\n",
      "6650 epch loss:  0.23048794    train accuracy:  [0.16]\n",
      "6700 epch loss:  0.22831884    train accuracy:  [0.172]\n",
      "6750 epch loss:  0.2288039    train accuracy:  [0.149]\n",
      "6800 epch loss:  0.22950535    train accuracy:  [0.1395]\n",
      "test accuracy:  [0.1275]\n",
      "6850 epch loss:  0.23102652    train accuracy:  [0.1365]\n",
      "6900 epch loss:  0.23219402    train accuracy:  [0.109]\n",
      "6950 epch loss:  0.23142773    train accuracy:  [0.119]\n",
      "7000 epch loss:  0.23064038    train accuracy:  [0.106]\n",
      "test accuracy:  [0.1495]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "7050 epch loss:  0.2319274    train accuracy:  [0.0785]\n",
      "7100 epch loss:  0.23160474    train accuracy:  [0.106]\n",
      "7150 epch loss:  0.23129223    train accuracy:  [0.1005]\n",
      "7200 epch loss:  0.23071672    train accuracy:  [0.124]\n",
      "test accuracy:  [0.1315]\n",
      "7250 epch loss:  0.22912788    train accuracy:  [0.1515]\n",
      "7300 epch loss:  0.22808214    train accuracy:  [0.1565]\n",
      "7350 epch loss:  0.22908139    train accuracy:  [0.14]\n",
      "7400 epch loss:  0.23070215    train accuracy:  [0.1275]\n",
      "test accuracy:  [0.1405]\n",
      "7450 epch loss:  0.23101377    train accuracy:  [0.107]\n",
      "7500 epch loss:  0.23128048    train accuracy:  [0.0995]\n",
      "7550 epch loss:  0.23091413    train accuracy:  [0.0995]\n",
      "7600 epch loss:  0.22980215    train accuracy:  [0.0995]\n",
      "test accuracy:  [0.1365]\n",
      "7650 epch loss:  0.23231292    train accuracy:  [0.1065]\n",
      "7700 epch loss:  0.23090027    train accuracy:  [0.102]\n",
      "7750 epch loss:  0.23183657    train accuracy:  [0.1205]\n",
      "7800 epch loss:  0.23007612    train accuracy:  [0.1715]\n",
      "test accuracy:  [0.14]\n",
      "7850 epch loss:  0.22797012    train accuracy:  [0.154]\n",
      "7900 epch loss:  0.22849026    train accuracy:  [0.1465]\n",
      "7950 epch loss:  0.22972064    train accuracy:  [0.152]\n",
      "8000 epch loss:  0.23019588    train accuracy:  [0.124]\n",
      "test accuracy:  [0.162]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "8050 epch loss:  0.23142657    train accuracy:  [0.108]\n",
      "8100 epch loss:  0.23060535    train accuracy:  [0.101]\n",
      "8150 epch loss:  0.23069544    train accuracy:  [0.115]\n",
      "8200 epch loss:  0.23167232    train accuracy:  [0.093]\n",
      "test accuracy:  [0.138]\n",
      "8250 epch loss:  0.23110376    train accuracy:  [0.1155]\n",
      "8300 epch loss:  0.23116875    train accuracy:  [0.1185]\n",
      "8350 epch loss:  0.22994824    train accuracy:  [0.1605]\n",
      "8400 epch loss:  0.22857217    train accuracy:  [0.162]\n",
      "test accuracy:  [0.1415]\n",
      "8450 epch loss:  0.22838537    train accuracy:  [0.148]\n",
      "8500 epch loss:  0.22993618    train accuracy:  [0.136]\n",
      "8550 epch loss:  0.23081943    train accuracy:  [0.1215]\n",
      "8600 epch loss:  0.23125422    train accuracy:  [0.126]\n",
      "test accuracy:  [0.124]\n",
      "8650 epch loss:  0.2307533    train accuracy:  [0.1155]\n",
      "8700 epch loss:  0.2305396    train accuracy:  [0.11]\n",
      "8750 epch loss:  0.23086908    train accuracy:  [0.0955]\n",
      "8800 epch loss:  0.23201594    train accuracy:  [0.106]\n",
      "test accuracy:  [0.154]\n",
      "8850 epch loss:  0.23140983    train accuracy:  [0.108]\n",
      "8900 epch loss:  0.23085566    train accuracy:  [0.1465]\n",
      "8950 epch loss:  0.2295943    train accuracy:  [0.168]\n",
      "9000 epch loss:  0.22838846    train accuracy:  [0.157]\n",
      "test accuracy:  [0.1465]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "9050 epch loss:  0.22934787    train accuracy:  [0.1365]\n",
      "9100 epch loss:  0.23047478    train accuracy:  [0.126]\n",
      "9150 epch loss:  0.23086067    train accuracy:  [0.123]\n",
      "9200 epch loss:  0.2311635    train accuracy:  [0.1075]\n",
      "test accuracy:  [0.1485]\n",
      "9250 epch loss:  0.23022854    train accuracy:  [0.1095]\n",
      "9300 epch loss:  0.23114786    train accuracy:  [0.1015]\n",
      "9350 epch loss:  0.23173706    train accuracy:  [0.106]\n",
      "9400 epch loss:  0.23062898    train accuracy:  [0.1235]\n",
      "test accuracy:  [0.149]\n",
      "9450 epch loss:  0.23083878    train accuracy:  [0.1415]\n",
      "9500 epch loss:  0.22899126    train accuracy:  [0.1645]\n",
      "9550 epch loss:  0.22770546    train accuracy:  [0.1685]\n",
      "9600 epch loss:  0.22827417    train accuracy:  [0.154]\n",
      "test accuracy:  [0.15]\n",
      "9650 epch loss:  0.2300667    train accuracy:  [0.1385]\n",
      "9700 epch loss:  0.2307458    train accuracy:  [0.1195]\n",
      "9750 epch loss:  0.23188387    train accuracy:  [0.117]\n",
      "9800 epch loss:  0.23056255    train accuracy:  [0.112]\n",
      "test accuracy:  [0.1415]\n",
      "9850 epch loss:  0.22994643    train accuracy:  [0.095]\n",
      "9900 epch loss:  0.23210657    train accuracy:  [0.1015]\n",
      "9950 epch loss:  0.23139472    train accuracy:  [0.1165]\n",
      "10000 epch loss:  0.2309731    train accuracy:  [0.111]\n",
      "test accuracy:  [0.17]\n",
      "INFO:tensorflow:datasets/Mnist/model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#关于evaluate部分，在训练过程中可以使用一部分数据集来验证模型的准确率，本程序将验证集合测试集视为相同。\n",
    "\n",
    "def evaluate(model_path, test_img):\n",
    "    img = tf.placeholder(tf.float32, shape=(28,28,3))\n",
    "    \n",
    "    net = network()\n",
    "    \n",
    "    predict = net.test(img)\n",
    "    predict = tf.nn.softmax(predict)\n",
    "    \n",
    "    label = tf.argmax(predcit,1)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        tf.train.Saver(max_to_keep=None).restore(sess, model_path)\n",
    "        pred, label = sess.run([predict, label], feed_dict={img:test_img})\n",
    "        \n",
    "        print(pred, label)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-10-293a1d9b8c02>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-293a1d9b8c02>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=log\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "image = './19.bmp'\n",
    "model_path = os.getcwd() +'/'+'model/model.ckpt'\n",
    "img = cv2.imread(image)\n",
    "evaluate(model_path,img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "from PIL import Image  #注意Image,后面会用到\n",
    "\n",
    "import os \n",
    "\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "data_path = \"datasets/cifar10/\"\n",
    "\n",
    "meta = unpickle(data_path + '/batches.meta')\n",
    "label_name = meta[b'label_names']\n",
    "\n",
    "for i in range(1,6):\n",
    "    content = unpickle(data_path + '/data_batch_' + str(i))\n",
    "    print('loading data...')\n",
    "    print(content.keys())\n",
    "    print('transforming data_batch' + str(i))\n",
    "    for j in range(10000):\n",
    "        img = content[b'data'][j]\n",
    "        img = img.reshape(3,32,32)\n",
    "        img = img.transpose(1,2,0)\n",
    "        \n",
    "        img_path = data_path + 'train/'+label_name[content[b'labels'][j]].decode()\n",
    "        if not os.path.isdir(img_path):\n",
    "            os.makedirs(img_path)\n",
    "            \n",
    "        img_name = img_path + '/batch_' + str(i) + '_num_' + str(j) +'.jpg'\n",
    "        \n",
    "        imsave(img_name,img)\n",
    "\n",
    "## test data\n",
    "content = unpickle(data_path + 'test_batch')\n",
    "print('loading data...')\n",
    "print(content.keys())\n",
    "print('transforming test_batch')\n",
    "for j in range(10000):\n",
    "    img = content[b'data'][j]\n",
    "    img = img.reshape(3,32,32)\n",
    "    img = img.transpose(1,2,0)\n",
    "        \n",
    "    img_path = data_path + 'test/'+label_name[content[b'labels'][j]].decode()\n",
    "    if not os.path.isdir(img_path):\n",
    "        os.makedirs(img_path)\n",
    "            \n",
    "    img_name = img_path + '/num_' +str(j) +'.jpg'\n",
    "        \n",
    "    imsave(img_name,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords\n",
    "TensorFlow可以支持cifar10的数据格式， 也提供了标准的TFRecord 格式，而关于 tensorflow 读取数据， 官网提供了3中方法 \n",
    "1 Feeding： 在tensorflow程序运行的每一步， 用python代码在线提供数据 \n",
    "2 Reader ： 在一个计算图（tf.graph）的开始前，将文件读入到流（queue）中 \n",
    "3 在声明tf.variable变量或numpy数组时保存数据。受限于内存大小，适用于数据较小的情况\n",
    "\n",
    "在本文，主要介绍第二种方法，利用tf.record标准接口来读入文件,训练时不再使用feed,而是事先将数据的读取也构建成图，将数据读取图的输出当作训练输入直接与训练图拼接再一起，不需要再使用tf.palceholder,这样训练时tf将直接从硬盘中读取数据\n",
    "\n",
    "tfrecord, 这是一种将图像数据和标签放在一起的二进制文件，能更好的利用内存，在tensorflow中快速的复制，移动，读取，存储 等等..\n",
    "tf.train.Example 协议内存块包含了Features字段，通过feature将图片的二进制数据和label进行统一封装， 然后将example协议内存块转化为字符串， tf.python_io.TFRecordWriter 写入到TFRecords文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/cifar10/\"\n",
    "classes = ['airplane','automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] \n",
    "\n",
    "def generate_tfrecords(data_path, filename):\n",
    "    writer= tf.python_io.TFRecordWriter(filename) #要生成的文件\n",
    "    for index in range(len(classes)):\n",
    "        class_path = data_path + classes[index] +'/'\n",
    "        \n",
    "        for img_name in os.listdir(class_path): \n",
    "            img_path=class_path+img_name #每一个图片的地址\n",
    "            \n",
    "            img=Image.open(img_path)\n",
    "            #img= img.resize((128,128))\n",
    "            img_raw=img.tobytes()#将图片转化为二进制格式\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n",
    "                'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n",
    "            })) #example对象对label和image数据进行封装\n",
    "            \n",
    "            writer.write(example.SerializeToString())  #序列化为字符串\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = data_dir + \"train/\"\n",
    "data_path_test = data_dir + \"test/\"\n",
    "\n",
    "train_tfrecords = data_path_train + \"cifar_train.tfrecords\"\n",
    "test_tfrecords = data_path_test + \"cifar_test.tfrecords\"\n",
    "\n",
    "#generate_tfrecords(data_path_train, train_tfrecords)\n",
    "#generate_tfrecords(data_path_test, test_tfrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取TFRECORD文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename): # 读入dog_train.tfrecords\n",
    "    filename_queue = tf.train.string_input_producer([filename])#生成一个queue队列\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)#返回文件名和文件\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                       })#将image数据和label取出来\n",
    "\n",
    "    img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "    img = tf.reshape(img, [32, 32, 3])  #reshape为32*32的3通道图片\n",
    "    img = tf.cast(img, tf.float32) * (1. / 255) - 0.5 #在流中抛出img张量\n",
    "    \n",
    "    label = tf.cast(features['label'], tf.int32) #在流中抛出label张量\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 注意，feature的属性“label”和“img_raw”名称要和制作时统一\n",
    "## 返回的img数据和label数据一一对应。返回的img和label是2个 tf 张量\n",
    "'''\n",
    "(<tf.Tensor 'sub:0' shape=(32, 32, 3) dtype=float32>,\n",
    " <tf.Tensor 'Cast_1:0' shape=() dtype=int32>)\n",
    "'''\n",
    "\n",
    "read_and_decode(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显示tfrecord格式的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = \"datasets/cifar10/train/\"\n",
    "\n",
    "filename_train = data_path_train + \"cifar_train.tfrecords\"\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([filename_train]) #读入流中\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)   #返回文件名和文件\n",
    "features = tf.parse_single_example(serialized_example,\n",
    "                                   features={\n",
    "                                       'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                       'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                   })  #取出包含image和label的feature对象\n",
    "\n",
    "image = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "image = tf.reshape(image, [32, 32, 3])\n",
    "label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "with tf.Session() as sess: #开始一个会话\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    ## \n",
    "    coord=tf.train.Coordinator()\n",
    "    threads= tf.train.start_queue_runners(coord=coord)\n",
    "    for i in range(10): ##  不使用epoch, 手动控制循环数量\n",
    "        example, l = sess.run([image,label])#在会话中取出image和label\n",
    "        img=Image.fromarray(example, 'RGB')#这里Image是之前提到的\n",
    "        img.save(data_path_train + str(i)+'_''Label_'+str(l)+'.jpg')#存下图片\n",
    "        #print(example, l)\n",
    "    ##     \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用TFrecord 数据训练\n",
    "注意是想向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    def __init__(self):\n",
    "        self.keep_prob = tf.constant(0.8)\n",
    "        \n",
    "    \n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.constant(0.1,shape=shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def conv2d(self, x,W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "    def max_pool_2x2(self, x): \n",
    "        return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "    def conv_layer(self, input, shape):\n",
    "        W = self.weight_variable(shape)\n",
    "        b = self.bias_variable([shape[3]]) # number of filters\n",
    "        return tf.nn.relu(self.conv2d(input,W) + b)\n",
    "\n",
    "    def full_layer(self, input, size):\n",
    "        in_size = int(input.get_shape()[1])\n",
    "        W = self.weight_variable([in_size,size])\n",
    "        b = self.bias_variable([size])\n",
    "        return tf.matmul(input,W) + b\n",
    "    \n",
    "    def model(self, img):\n",
    "        conv1_1 = self.conv_layer(img,shape=[3,3,3,32])\n",
    "        conv1_2 = self.conv_layer(conv1_1,shape=[3,3,32,32])\n",
    "        conv1_3 = self.conv_layer(conv1_2,shape=[3,3,32,32])\n",
    "        conv1_pool = self.max_pool_2x2(conv1_3) # 16,32\n",
    "        conv1_drop = tf.nn.dropout(conv1_pool,keep_prob=self.keep_prob)\n",
    "\n",
    "        conv2_1 = self.conv_layer(conv1_drop,shape=[3,3,32,64])\n",
    "        conv2_2 = self.conv_layer(conv2_1,shape=[3,3,64,64])\n",
    "        conv2_3 = self.conv_layer(conv2_2,shape=[3,3,64,64])\n",
    "        conv2_pool = self.max_pool_2x2(conv2_3) # 8,64\n",
    "        conv2_drop = tf.nn.dropout(conv2_pool,keep_prob=self.keep_prob)\n",
    "\n",
    "        conv3_1 = self.conv_layer(conv2_drop,shape=[3,3,64,128])\n",
    "        conv3_2 = self.conv_layer(conv3_1,shape=[3,3,128,128])\n",
    "        conv3_3 = self.conv_layer(conv3_2,shape=[3,3,128,128])\n",
    "        conv3_pool = tf.nn.max_pool(conv3_3, ksize=(1,8,8,1), strides=(1,8,8,1), padding='SAME') # 1,128\n",
    "        conv3_flat = tf.reshape(conv3_pool, [-1,128])\n",
    "        conv3_drop = tf.nn.dropout(conv3_flat,keep_prob=self.keep_prob)\n",
    "\n",
    "        full1 = tf.nn.relu(self.full_layer(conv3_drop, 600))\n",
    "        full1_drop = tf.nn.dropout(full1, keep_prob=self.keep_prob)\n",
    "\n",
    "        yout = self.full_layer(full1_drop,10)\n",
    "        \n",
    "        return yout\n",
    "    \n",
    "    def test(self, img):\n",
    "        img = tf.reshape(img, shape=[-1,32,32,3])\n",
    "        \n",
    "        conv1_1 = self.conv_layer(img,shape=[3,3,3,32])\n",
    "        conv1_2 = self.conv_layer(conv1_1,shape=[3,3,32,32])\n",
    "        conv1_3 = self.conv_layer(conv1_2,shape=[3,3,32,32])\n",
    "        conv1_pool = self.max_pool_2x2(conv1_3) # 16,32\n",
    "        conv1_drop = tf.nn.dropout(conv1_pool,keep_prob=1)\n",
    "\n",
    "        conv2_1 = self.conv_layer(conv1_drop,shape=[3,3,32,64])\n",
    "        conv2_2 = self.conv_layer(conv2_1,shape=[3,3,64,64])\n",
    "        conv2_3 = self.conv_layer(conv2_2,shape=[3,3,64,64])\n",
    "        conv2_pool = self.max_pool_2x2(conv2_3) # 8,64\n",
    "        conv2_drop = tf.nn.dropout(conv2_pool,keep_prob=1)\n",
    "\n",
    "        conv3_1 = self.conv_layer(conv2_drop,shape=[3,3,64,128])\n",
    "        conv3_2 = self.conv_layer(conv3_1,shape=[3,3,128,128])\n",
    "        conv3_3 = self.conv_layer(conv3_2,shape=[3,3,128,128])\n",
    "        conv3_pool = tf.nn.max_pool(conv3_3, ksize=(1,8,8,1), strides=(1,8,8,1), padding='SAME') # 1,128\n",
    "        conv3_flat = tf.reshape(conv3_pool, [-1,128])\n",
    "        conv3_drop = tf.nn.dropout(conv3_flat,keep_prob=1)\n",
    "\n",
    "        full1 = tf.nn.relu(self.full_layer(conv3_drop, 600))\n",
    "        full1_drop = tf.nn.dropout(full1, keep_prob=1)\n",
    "\n",
    "        test_out = self.full_layer(full1_drop,10)\n",
    "        \n",
    "        return test_out\n",
    "    \n",
    "    def softmax_loss(self, yout, labels):\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=yout,labels=labels))\n",
    "        \n",
    "        return cross_entropy\n",
    "    \n",
    "    def optimizer(self, loss, lr=1e-3):\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "        \n",
    "        return train_step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(steps, batch_size):\n",
    "    img, label = read_and_decode(train_tfrecords)\n",
    "    img_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [img, label], num_threads=10, batch_size=batch_size,\n",
    "        capacity=50000, min_after_dequeue=40000)\n",
    "    \n",
    "    # label must be one-hot array!!\n",
    "    label_batch = tf.one_hot(label_batch, 10)\n",
    "    \n",
    "    net = network()\n",
    "    yout = net.model(img_batch)\n",
    "    loss = net.softmax_loss(yout, label_batch)\n",
    "    opti = net.optimizer(loss)\n",
    "    \n",
    "    train_correct = tf.equal(tf.cast(tf.argmax(yout,1), tf.int32),\n",
    "                             tf.cast(tf.argmax(label_batch,1), tf.int32))\n",
    "    \n",
    "    train_accuracy = tf.reduce_mean(tf.cast(train_correct, tf.float32))\n",
    "    \n",
    "    ## evaluate ####\n",
    "    test_img, test_label = read_and_decode(test_tfrecords)\n",
    "    test_img_batch, test_label_batch = tf.train.shuffle_batch(\n",
    "        [test_img, test_label], num_threads=10, batch_size=batch_size,\n",
    "        capacity=10000, min_after_dequeue=9000)\n",
    "    \n",
    "    test_label_batch = tf.one_hot(test_label_batch,10)\n",
    "    \n",
    "    test_out = net.test(test_img_batch)\n",
    "    test_correct = tf.equal(tf.cast(tf.argmax(test_out,1), tf.int32),\n",
    "                             tf.cast(tf.argmax(test_label_batch,1), tf.int32))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(test_correct, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.group(tf.global_variables_initializer(), \n",
    "                           tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        coord = tf.train.Coordinator()\n",
    "        \n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        ## 注意sess.run的输出名一定不能和输入名相同！！\n",
    "        for i in range(1, steps+1):\n",
    "            loss_out, _, train_acc= sess.run([loss, opti, train_accuracy])\n",
    "            \n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(\"{}  loss: {} train_acc: {:.4}%\".format(i, loss_out, train_acc*100))\n",
    "                \n",
    "            if i%500 == 0:\n",
    "                test_acc = sess.run([test_accuracy])\n",
    "                ##print(\"test acc: {:.4}%\".format(test_acc*100))\n",
    "                print(test_acc)\n",
    "            \n",
    "        \n",
    "        # when done, ask the treads to stop.\n",
    "        coord.request_stop()\n",
    "        ## wait for threads to finish\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-82889d971bc6>:89: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "100  loss: 2.2404778003692627 train_acc: 16.5%\n",
      "200  loss: 2.0857760906219482 train_acc: 17.5%\n",
      "300  loss: 1.8969630002975464 train_acc: 22.6%\n",
      "400  loss: 1.7208993434906006 train_acc: 32.6%\n",
      "500  loss: 1.672035574913025 train_acc: 38.3%\n",
      "[0.103]\n",
      "600  loss: 1.5458639860153198 train_acc: 41.8%\n",
      "700  loss: 1.5012085437774658 train_acc: 44.1%\n",
      "800  loss: 1.5450233221054077 train_acc: 44.5%\n",
      "900  loss: 1.3860194683074951 train_acc: 49.0%\n",
      "1000  loss: 1.3118430376052856 train_acc: 54.4%\n",
      "[0.095]\n",
      "1100  loss: 1.2153669595718384 train_acc: 55.2%\n",
      "1200  loss: 1.18802011013031 train_acc: 56.9%\n",
      "1300  loss: 1.1034505367279053 train_acc: 60.1%\n",
      "1400  loss: 1.117480754852295 train_acc: 59.8%\n",
      "1500  loss: 1.0607857704162598 train_acc: 60.7%\n",
      "[0.162]\n",
      "1600  loss: 1.0471934080123901 train_acc: 62.2%\n",
      "1700  loss: 0.9612636566162109 train_acc: 65.0%\n",
      "1800  loss: 0.8475262522697449 train_acc: 69.8%\n",
      "1900  loss: 0.9090547561645508 train_acc: 67.8%\n",
      "2000  loss: 0.8267858624458313 train_acc: 70.6%\n",
      "[0.149]\n",
      "2100  loss: 0.8271371722221375 train_acc: 70.9%\n",
      "2200  loss: 0.7330003976821899 train_acc: 74.2%\n",
      "2300  loss: 0.7999044060707092 train_acc: 71.8%\n",
      "2400  loss: 0.7772341370582581 train_acc: 72.5%\n",
      "2500  loss: 0.7478119134902954 train_acc: 73.1%\n",
      "[0.143]\n",
      "2600  loss: 0.7084106206893921 train_acc: 76.6%\n",
      "2700  loss: 0.7401860952377319 train_acc: 74.6%\n",
      "2800  loss: 0.6527765989303589 train_acc: 77.2%\n",
      "2900  loss: 0.6363753080368042 train_acc: 77.5%\n",
      "3000  loss: 0.6259632706642151 train_acc: 78.0%\n",
      "[0.151]\n",
      "3100  loss: 0.613501787185669 train_acc: 76.7%\n",
      "3200  loss: 0.603925883769989 train_acc: 79.3%\n",
      "3300  loss: 0.5745298266410828 train_acc: 80.1%\n",
      "3400  loss: 0.5291222929954529 train_acc: 81.4%\n",
      "3500  loss: 0.52589350938797 train_acc: 81.4%\n",
      "[0.114]\n",
      "3600  loss: 0.5470019578933716 train_acc: 80.9%\n",
      "3700  loss: 0.5800172686576843 train_acc: 80.6%\n",
      "3800  loss: 0.5220916867256165 train_acc: 80.6%\n",
      "3900  loss: 0.48427122831344604 train_acc: 83.0%\n",
      "4000  loss: 0.4743427634239197 train_acc: 84.2%\n",
      "[0.116]\n",
      "4100  loss: 0.45334669947624207 train_acc: 85.4%\n",
      "4200  loss: 0.4771638810634613 train_acc: 83.5%\n",
      "4300  loss: 0.4256322979927063 train_acc: 84.6%\n",
      "4400  loss: 0.4214404225349426 train_acc: 84.7%\n",
      "4500  loss: 0.4478900134563446 train_acc: 84.8%\n",
      "[0.093]\n",
      "4600  loss: 0.37111514806747437 train_acc: 87.9%\n",
      "4700  loss: 0.3682582974433899 train_acc: 85.8%\n",
      "4800  loss: 0.36821550130844116 train_acc: 85.3%\n",
      "4900  loss: 0.39610135555267334 train_acc: 85.8%\n",
      "5000  loss: 0.3820902705192566 train_acc: 86.0%\n",
      "[0.08]\n"
     ]
    }
   ],
   "source": [
    "# batch size 太小很容易过拟合，并且loss 波动较大\n",
    "# 为了防止过拟合，capacity 也要大一些\n",
    "# batch size 越大，学习率也要大一些\n",
    "batch_size = 1000 \n",
    "steps =5000   # 50000/1000=50\n",
    "\n",
    "train(steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入数据集时设定epoch数量,几个epoch就要把整个数据集读入几次\n",
    "# 训练时就不必再设定循环次数，\n",
    "filename_train_queue = tf.train.string_input_producer(\n",
    "    [filename_train], num_epochs=num_epochs) \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "        \n",
    "    ##### coordinator ####\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    try:\n",
    "        step = 0\n",
    "        ## 事先已设定了epoch,不再需要控制循环次数\n",
    "        while not coord.should_stop():\n",
    "            step += 1\n",
    "            image_batch, label_batch = sess.run([images_batch_train, tf.one_hot(labels_batch_train,depth=10)])\n",
    "        \n",
    "            feed = {x:image_batch, y:label_batch, keep_prob:0.5}\n",
    "            # loss,_,acc=session.run([cross_entropy,train_step,accuracy], feed_dict=feed)\n",
    "            sess.run(train_step, feed_dict=feed, )\n",
    "        \n",
    "            if step%100 == 0:\n",
    "                loss = sess.run(cross_entropy, feed_dict=feed)\n",
    "                train_accuracy = sess.run(accuracy, feed_dict={x:image_batch, y:label_batch, keep_prob:1.0})\n",
    "                print(\"step {} loss: {}, train_acc: {:.4}%\".format(step, loss, train_accuracy*100))\n",
    "        \n",
    "            if step>1500:\n",
    "                learning_rate = learning_rate * 0.5\n",
    "        \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (num_epochs, step))\n",
    "    \n",
    "    finally:\n",
    "\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size =100\n",
    "data_path = \"datasets/cifar10/test/\"\n",
    "\n",
    "filename = data_path + \"cifar_test.tfrecords\"\n",
    "\n",
    "filename_train_queue = tf.train.string_input_producer(\n",
    "    [filename_train], num_epochs=num_epochs) #读入流中, 并设定epoch数量\n",
    "\n",
    "reader_train = tf.TFRecordReader()\n",
    "\n",
    "_, serialized_example_train = reader_train.read(filename_train_queue)   #返回文件名和文件\n",
    "\n",
    "features_train = tf.parse_single_example(serialized_example_train,\n",
    "                                   features={\n",
    "                                       'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                       'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                   })  #取出包含image和label的feature对象\n",
    "\n",
    "image_train = tf.decode_raw(features_train['img_raw'], tf.uint8)\n",
    "image_train = tf.reshape(image_train, [32, 32, 3])\n",
    "image_train = tf.cast(image_train, tf.float32)*(1./255) - 0.5\n",
    "label_train = tf.cast(features_train['label'], tf.int32)\n",
    "\n",
    "images_batch_train, labels_batch_train = tf.train.shuffle_batch(\n",
    "    [image_train, label_train], batch_size=batch_size, \n",
    "    capacity=2000, \n",
    "    min_after_dequeue=1000)\n",
    "        \n",
    "        X = cifar.test.images.reshape(10,1000,32,32,3)\n",
    "        Y = cifar.test.labels.reshape(10,1000,10)\n",
    "        \n",
    "        test_accuracy = np.mean([sess.run(accuracy, feed_dict={x:X[i], y:Y[i], keep_prob:1.0}) for i in range(10)])\n",
    "        print(\"test_acc: {}\".format(test_accuracy))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

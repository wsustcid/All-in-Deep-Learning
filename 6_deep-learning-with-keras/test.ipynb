{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building powerful image classification models using very little data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 A Small ConvNet \n",
    "As a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/media/ubuntu16/Documents/datasets/dogs-vs-cats-2000/train/'\n",
    "validation_data_dir = '/media/ubuntu16/Documents/datasets/dogs-vs-cats-2000/validation'\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# generate batches of image data (and their labels) directly from our jpgs in their respective folders.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "#model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fine-tuning a pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/media/ubuntu16/Documents/datasets/dogs-vs-cats-2000/train/'\n",
    "validation_data_dir = '/media/ubuntu16/Documents/datasets/dogs-vs-cats-2000/validation/'\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# generate batches of image data (and their labels) directly from our jpgs in their respective folders.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# 构建不带分类器的预训练模型\n",
    "# 因不包含top层，输入维度不用固定\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# \n",
    "x = base_model.output \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Flatten(input_shape=base_model.output_shape[1:])(x)\n",
    "\n",
    "# 添加全连接层\n",
    "x = Dense(256, activation='relu', name='dense_1')(x)\n",
    "\n",
    "# 添加分类器 (二分类使用sigmoid, 多分类使用softmoax)\n",
    "predictions = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "# 构建完整模型\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# 首先，锁住预训练好的卷积层， 仅训练顶部的两层\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = False\n",
    "    print(i,layer.name)\n",
    "    \n",
    "# 编译模型，一定要在锁层以后操作\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 在新的数据集上训练\n",
    "hist_top = model.fit_generator(train_generator,\n",
    "                               samples_per_epoch=nb_train_samples//batch_size,\n",
    "                               epochs = epochs,\n",
    "                               verbose = 1,\n",
    "                               validation_data = validation_generator,\n",
    "                               validation_steps= nb_validation_samples//batch_size)\n",
    "\n",
    "\n",
    "# 微调VGG16部分卷积层\n",
    "# 通过查看各层编号和名字，锁住前15层，训练之后的层\n",
    "# 不能微调所有层，因为整个网络的表示能力过于强大，很容易过拟合\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# 重新编译模型，使设置生效 （注意使用sgd）\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# fine-tune the model\n",
    "hist_tune = model.fit_generator(train_generator,\n",
    "                               samples_per_epoch=nb_train_samples//batch_size,\n",
    "                               epochs = epochs,\n",
    "                               verbose = 1,\n",
    "                               validation_data = validation_generator,\n",
    "                               validation_steps= nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2,1, figsize=(10, 20))\n",
    "axes[0].plot(hist_top.history['loss'], label='train')\n",
    "axes[0].plot(hist_top.history['val_loss'], label='validation')\n",
    "\n",
    "axes[1].plot(hist_tune.history['loss'], label='train')\n",
    "axes[1].plot(hist_tune.history['val_loss'], label='validation')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16 \n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "print(len(base_model.layers))\n",
    "print()\n",
    "print(base_model.inputs) # 模型输入张量的列表，可能由多个输入\n",
    "print(base_model.input)\n",
    "print()\n",
    "print(base_model.outputs) # 模型输入张量的列表，可能由多个输入\n",
    "print(base_model.output)\n",
    "print()\n",
    "print(base_model.input_shape)\n",
    "print(base_model.output_shape)\n",
    "print()\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training using single GPU or CPU..\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2453 - acc: 0.9246 - val_loss: 0.1013 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.92463, saving model to best_model.h5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1038 - acc: 0.9687 - val_loss: 0.0910 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00002: acc improved from 0.92463 to 0.96872, saving model to best_model.h5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0755 - acc: 0.9773 - val_loss: 0.0771 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00003: acc improved from 0.96872 to 0.97728, saving model to best_model.h5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0608 - acc: 0.9815 - val_loss: 0.0784 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00004: acc improved from 0.97728 to 0.98152, saving model to best_model.h5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0533 - acc: 0.9843 - val_loss: 0.0744 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00005: acc improved from 0.98152 to 0.98433, saving model to best_model.h5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0438 - acc: 0.9870 - val_loss: 0.0758 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00006: acc improved from 0.98433 to 0.98697, saving model to best_model.h5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0371 - acc: 0.9889 - val_loss: 0.0912 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00007: acc improved from 0.98697 to 0.98885, saving model to best_model.h5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0341 - acc: 0.9900 - val_loss: 0.0740 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00008: acc improved from 0.98885 to 0.99005, saving model to best_model.h5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0319 - acc: 0.9908 - val_loss: 0.0877 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00009: acc improved from 0.99005 to 0.99085, saving model to best_model.h5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0280 - acc: 0.9917 - val_loss: 0.0836 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00010: acc improved from 0.99085 to 0.99170, saving model to best_model.h5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0270 - acc: 0.9922 - val_loss: 0.0907 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00011: acc improved from 0.99170 to 0.99220, saving model to best_model.h5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0240 - acc: 0.9929 - val_loss: 0.0930 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00012: acc improved from 0.99220 to 0.99287, saving model to best_model.h5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0238 - acc: 0.9932 - val_loss: 0.1017 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00013: acc improved from 0.99287 to 0.99323, saving model to best_model.h5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0211 - acc: 0.9941 - val_loss: 0.1015 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00014: acc improved from 0.99323 to 0.99410, saving model to best_model.h5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0209 - acc: 0.9942 - val_loss: 0.1134 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00015: acc improved from 0.99410 to 0.99422, saving model to best_model.h5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0211 - acc: 0.9943 - val_loss: 0.1020 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00016: acc improved from 0.99422 to 0.99433, saving model to best_model.h5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0202 - acc: 0.9949 - val_loss: 0.1050 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00017: acc improved from 0.99433 to 0.99492, saving model to best_model.h5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0204 - acc: 0.9950 - val_loss: 0.1096 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00018: acc improved from 0.99492 to 0.99497, saving model to best_model.h5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0188 - acc: 0.9953 - val_loss: 0.1002 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00019: acc improved from 0.99497 to 0.99527, saving model to best_model.h5\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0184 - acc: 0.9952 - val_loss: 0.1078 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.99527\n",
      "Test loss: 0.10022274801477445\n",
      "Test accuracy: 0.9853\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    " \n",
    "from __future__ import print_function\n",
    " \n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))\n",
    " \n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "num_gpu=8\n",
    " \n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    " \n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# float64 is not supported in GPU\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    " \n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "try:\n",
    "    parallel_model = multi_gpu_model(model, gpus=num_gpu, cpu_relocation=True)\n",
    "    print(\"Training using multiple GPUs..\")\n",
    "except ValueError:\n",
    "    parallel_model = model\n",
    "    print(\"Training using single GPU or CPU..\")\n",
    "    \n",
    " \n",
    " \n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=RMSprop(),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='acc', save_best_only=True, verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint]\n",
    "history = parallel_model.fit(x_train, y_train,\n",
    "                             batch_size=batch_size,\n",
    "                             epochs=epochs,\n",
    "                             verbose=1,\n",
    "                             validation_data=(x_test, y_test),\n",
    "                             callbacks=callbacks)\n",
    "\n",
    "best_model = load_model('best_model.h5')\n",
    "score = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 使用 float64, 显存占满，GPU利用率40%左右\n",
    "2. 使用float32, 显存占满，GPU利用率44%左右"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

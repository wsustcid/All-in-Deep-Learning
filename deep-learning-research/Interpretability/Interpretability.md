# Interpretability of Neural Networks

## 1. Introduction

### 深度学习的可解释性研究

*文章来源：知乎用户王小贱 -- 北航BIGSCity研究组*

#### 基本概念

**可解释性定义：**

Interpretation is the process of giving explanations **to Human**.

**为什么需要可解释性：**

- 我们希望知道模型究竟从数据中学到了哪些知识（以人类可以理解的方式表达的）从而产生了最终的决策。
- 不可解释同样也意味着**危险**，如对抗样本。具备可解释性的模型在面对这些问题的时候是可以对异常产生的原因进行追踪和定位的
- *可解释的必要性也存在争议*

**可解释性方法（根据可解释性方法进行的过程划分）**

- 在建模之前的可解释性方法
- 建立本身具备可解释性的模型
- 在建模之后使用可解释性方法对模型作出解释

#### 在建模之前的可解释性方法

这一类方法其实主要涉及一些数据预处理或数据展示的方法。机器学习解决的是从数据中发现知识和规律的问题，在建模之前的可解释性方法的关键在于帮助我们**迅速而全面地了解数据分布的特征**，从而帮助我们考虑在建模过程中可能面临的问题并选择一种最合理的模型来逼近问题所能达到的最优解。

**数据可视化：**

在真正要研究一个数据问题之前，通过建立一系列方方面面的可视化方法来**建立我们对数据的直观理解**是非常必须的，特别是当数据量非常大或者数据维度非常高的时候，比如一些时空高维数据，如果可以建立一些交互式的可视化方法将会极大地帮助我们**从各个层次角度理解数据的分布**。

**探索性质的数据分析：**

帮助我们更好地理解数据的分布情况。比如一种称为MMD-critic方法中，可以帮助我们找到数据中一些具有代表性或者不具代表性的样本。
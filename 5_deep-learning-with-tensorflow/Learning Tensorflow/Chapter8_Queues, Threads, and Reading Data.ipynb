{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Input Pipeline\n",
    "When dealing with small datasets that can be stored in memory, such as MNIST\n",
    "images, it is reasonable to simply load all data into memory, then use feeding to push\n",
    "data into a TensorFlow graph. For larger datasets, however, this can become\n",
    "unwieldy. A natural paradigm for handling such cases is to keep the data on disk and\n",
    "load chunks of it as needed (such as mini-batches for training), such that the only\n",
    "limit is the size of your hard drive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords\n",
    "A TFRecord file is simply a binary file, con‐\n",
    "taining serialized input data. Serialization is based on protocol buffers (proto‐\n",
    "bufs), which in plain words convert data for storage by using a schema describing the\n",
    "data structure, independently of what platform or language is being used (much like\n",
    "XML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, we download the MNIST data to save_dir\n",
    "# using a utility function from tensor flow.contrib.learn\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir =\"datasets/mnist\"\n",
    "\n",
    "# download data to save_dir and read it\n",
    "data_sets = mnist.read_data_sets(save_dir, dtype=tf.uint8, \n",
    "                                  reshape=False, validation_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sets)\n",
    "print(len(data_sets))\n",
    "print(\"  \")\n",
    "print(data_sets[0].images.shape)\n",
    "print(data_sets[0].labels.shape)\n",
    "print(data_sets[1].images.shape)\n",
    "print(data_sets[1].labels.shape)\n",
    "print(data_sets[2].images.shape)\n",
    "print(data_sets[2].labels.shape)\n",
    "print(\"  \")\n",
    "\n",
    "print(data_sets[0].images[58999,27,27,0])# numpy array (59000,28,28,1)\n",
    "print(data_sets[0].labels[58999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = [\"train\", \"validation\", \"test\"]\n",
    "for d in range(len(data_splits)):\n",
    "    print(\"saving \" + data_splits[d])\n",
    "    data_set = data_sets[d]\n",
    "    \n",
    "    # instantiate a TFRecordWriter object, \n",
    "    # giving it the path corresponding to the data split\n",
    "    filename = os.path.join(save_dir, data_splits[d] + '.tfrecords')\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for index in range(data_set.images.shape[0]):\n",
    "        # go over each image, converting it from a NumPy array to a byte string\n",
    "        #转化自己数据的时候可以直接一张张图片读取，不用一次读成4维的矩阵\n",
    "        image = data_set.images[index].tostring()\n",
    "        \n",
    "        '''\n",
    "        Next, we convert images to their protobuf format. tf.train.Example is a structure\n",
    "        for storing our data. An Example object contains a Features object, which in turn\n",
    "        contains a map from attribute name to a Feature . A Feature can contain an\n",
    "        Int64List , a BytesList , or a FloatList (not used here).\n",
    "        '''\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[data_set.images.shape[1]])),\n",
    "            'width': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[data_set.images.shape[2]])),\n",
    "            'depth': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[data_set.images.shape[3]])),\n",
    "            'label': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[int(data_set.labels[index])])),\n",
    "            'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "                value=[image]))\n",
    "        }))\n",
    "        \n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    writer.close()\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let’s take a look at what our saved data looks like. We do this with\n",
    "tf.python_io.tf_record_iterator , an iterator that reads records from \n",
    "a TFRecords file\n",
    "'''\n",
    "filename = os.path.join(save_dir, 'train.tfrecords')\n",
    "record_iterator = tf.python_io.tf_record_iterator(filename)\n",
    "seralized_img_example = next(record_iterator)\n",
    "\n",
    "'''\n",
    "serialized_img is a byte string. To recover the structure we used when saving the\n",
    "image to a TFRecord, we parse this byte string, allowing us to access all the attributes\n",
    "we stored earlier:\n",
    "'''\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(seralized_img_example)\n",
    "\n",
    "image = example.features.feature['image_raw'].bytes_list.value\n",
    "label = example.features.feature['label'].int64_list.value[0]\n",
    "width = example.features.feature['width'].int64_list.value[0]\n",
    "height = example.features.feature['height'].int64_list.value[0]\n",
    "\n",
    "'''\n",
    "Our image was saved as a byte string too, so we convert it back to a NumPy array and\n",
    "reshape it back to a tensor with shape (28,28,1):\n",
    "'''\n",
    "img_flat = np.fromstring(image[0], dtype=np.uint8)\n",
    "img_reshaped = img_flat.reshape((height,width,-1))\n",
    "img_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queues\n",
    "A TensorFlow queue is similar to an ordinary queue, allowing us to enqueue new\n",
    "items, dequeue existing items, etc. The important difference from ordinary queues is\n",
    "that, just like anything else in TensorFlow, the queue is part of a computational graph.\n",
    "Its operations are symbolic as usual, and other nodes in the graph can alter its state\n",
    "(much like with Variables). This can be slightly confusing at first, so let’s walk through\n",
    "some examples to get acquainted with basic queue functionalities.\n",
    "### Enqueuing and Dequeuing\n",
    "Here we create a first-in, first-out (FIFO) queue of strings, with a maximal number of\n",
    "10 elements that can be stored in the queue. Since queues are part of a computational\n",
    "graph, they are run within a session. In this example, we use a tf.InteractiveSes\n",
    "sion() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue1 = tf.FIFOQueue(capacity=10, dtypes=[tf.string])\n",
    "# Behind the scenes, TensorFlow creates a memory buffer for storing the 10 items.\n",
    "\n",
    "# Just like any other operation in TensorFlow, \n",
    "# to add items to the queue, we create an op:\n",
    "enque_op = queue1.enqueue([\"F\"])\n",
    "\n",
    "# before running the op\n",
    "sess.run(queue1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the op, our queue now has one item populating it:\n",
    "enque_op.run()\n",
    "sess.run(queue1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add some more items to queue1, and look at its sieze again:\n",
    "enque_op = queue1.enqueue([\"I\"])\n",
    "enque_op.run()\n",
    "enque_op = queue1.enqueue([\"F\"])\n",
    "enque_op.run()\n",
    "enque_op = queue1.enqueue([\"O\"])\n",
    "enque_op.run()\n",
    "\n",
    "sess.run(queue1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we dequeue items. Dequeuing too is an op, \n",
    "# whose output evaluates to a tensor corresponding to the dequeued item:\n",
    "\n",
    "x = queue1.dequeue()\n",
    "x.eval()\n",
    "\n",
    "'''\n",
    "Note that if we were to run xs.eval() one more time, on an empty queue, our main\n",
    "thread would hang forever. As we will see later in this chapter, in practice we use code\n",
    "that knows when to stop dequeuing and avoid hanging.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Another way to dequeue is by retrieving multiple items at once, with the\n",
    "dequeue_many() operation. This op requires that we specify the shape of items in\n",
    "advance:\n",
    "'''\n",
    "queue1 = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "\n",
    "inputs = queue1.dequeue_many(3)\n",
    "inputs.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "A TensorFlow session is multithreaded—multiple threads can use the same session\n",
    "and run ops in parallel. Individual ops have parallel implementations that are used by\n",
    "default with multiple CPU cores or GPU threads. However, if a single call to\n",
    "sess.run() does not make full use of the available resources, one can increase\n",
    "throughput by making multiple parallel calls. For example, in a typical scenario, we\n",
    "may have multiple threads apply pre-processing to images and push them into a\n",
    "queue, while another thread pulls pre-processed images from the queue for training\n",
    "(in the next chapter, we will discuss distributed training, which is conceptually\n",
    "related, with important differences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    " Note, again, that the enque op does not actually add the random numbers to the\n",
    "queue (and they are not yet generated) prior to graph execution. Items will be\n",
    "enqueued using the function add() we create that adds 10 items to the queue by call‐\n",
    "ing sess.run() multiple times.\n",
    " '''\n",
    "#import threading\n",
    "#import time\n",
    "\n",
    "gen_random_normal = tf.random_normal(shape=())\n",
    "queue = tf.FIFOQueue(capacity=100, dtypes=[tf.float32], shapes=())\n",
    "enque = queue.enqueue(gen_random_normal)\n",
    "\n",
    "def add():\n",
    "    for i in range(10):\n",
    "        sess.run(enque)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next, we create 10 threads, each running add() in parallel, thus each pushing 10\n",
    "items to the queue, asynchronously. We could think (for now) of these random num‐\n",
    "bers as training data being added into a queue:\n",
    "'''\n",
    "\n",
    "threads = [threading.Thread(target=add, args=()) for i in range(10)]\n",
    "\n",
    "threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We have created a list of threads, and now we execute them, printing the size of the\n",
    "queue at short intervals as it grows from 0 to 100:\n",
    "'''\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.01)\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.01)\n",
    "print(sess.run(queue.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = queue.dequeue_many(10)\n",
    "print(x.eval())\n",
    "sess.run(queue.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinator and QueueRunner\n",
    "In realistic scenarios (as we shall see later in this chapter), it can be more complicated\n",
    "to run multiple threads effectively. Threads should be able to stop properly (to avoid\n",
    "“zombie” threads, for example, or to close all threads together when one fails), queues\n",
    "need to be closed after stopping, and there are other technical but important issues\n",
    "that need to be addressed.\n",
    "\n",
    "TensorFlow comes equipped with tools to help us in this process. Key among them\n",
    "are tf.train.Coordinator , for coordinating the termination of a set of threads, and\n",
    "tf.train.QueueRunner , which streamlines the process of getting multiple threads to\n",
    "enqueue data with seamless cooperation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_random_normal = tf.random_normal(shape=())\n",
    "\n",
    "queue = tf.FIFOQueue(capacity=100, dtypes=[tf.float32], shapes=[])\n",
    "enque = queue.enqueue(gen_random_normal)\n",
    "\n",
    "def add(coord, i):\n",
    "    # Any thread can call coord.request_stop() to get all other threads to stop.\n",
    "    while not coord.should_stop():\n",
    "        sess.run(enque)\n",
    "        if i == 11:\n",
    "            coord.should_stop()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "threads = [threading.Thread(target=add, args=(coord,i)) for i in range(10)] \n",
    "\n",
    "coord.join(threads)\n",
    "\n",
    "#启动时顺序启动，但一旦启动便是并行运行？\n",
    "for t in threads:\n",
    "    t.start()\n",
    "    \n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.01)\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.01)\n",
    "print(sess.run(queue.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can create a number of threads that repeatedly run an enqueue op, it is bet‐\n",
    "ter practice to use the built-in tf.train.QueueRunner , which does exactly that, while\n",
    "closing the queue upon an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this example, we used a tf.RandomShuffleQueue rather than the FIFO queue. A\n",
    "RandomShuffleQueue is simply a queue with a dequeue op that pops items in random\n",
    "order. This is useful when training deep neural networks with stochastic gradient-\n",
    "descent optimization, which requires shuffling the data. \n",
    "The min_after_dequeue argument specifies the minimum number of items that will remain in the queue after\n",
    "calling a dequeue op—a bigger number entails better mixing (random sampling), but\n",
    "more memory.\n",
    "'''\n",
    "\n",
    "# Here we create a queue runner that will run \n",
    "# four threads in parallel to enqueue items:\n",
    "\n",
    "gen_random_normal = tf.random_normal(shape=())\n",
    "queue = tf.RandomShuffleQueue(capacity=100, dtypes=[tf.float32], min_after_dequeue=1)\n",
    "\n",
    "enqueue_op = queue.enqueue(gen_random_normal)\n",
    "\n",
    "queue_run = tf.train.QueueRunner(queue, [enqueue_op]*4)\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "enqueue_threads = queue_run.create_threads(sess, coord=coord, start=True)\n",
    "\n",
    "coord.request_stop()\n",
    "\n",
    "coord.join(enqueue_threads)\n",
    "\n",
    "print(sess.run(queue.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Full Multithreaded Input Pipeline\n",
    "We now put all the pieces together in a working example with MNIST images, from\n",
    "writing data to TensorFlow’s efficient file format, through data loading and pre-\n",
    "processing, to training a model. We do so by building on the queuing and multi‐\n",
    "threading functionality demonstrated earlier, and along the way introduce some more\n",
    "useful components for reading and processing data in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we write the MNIST data to TFRecords\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8fce757ee4ed>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/desktop/tensorflow/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/desktop/tensorflow/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/desktop/tensorflow/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/desktop/tensorflow/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "savingtrain\n",
      "savingvalidation\n",
      "savingtest\n"
     ]
    }
   ],
   "source": [
    "###### Write TFrecords #####\n",
    "save_dir = \"datasets/mnist\"\n",
    "\n",
    "data_sets = mnist.read_data_sets(save_dir,\n",
    "                                 dtype=tf.uint8,\n",
    "                                 reshape=False,\n",
    "                                 validation_size=1000)\n",
    "\n",
    "data_splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "for d in range(len(data_splits)):\n",
    "    print(\"saving\" + data_splits[d])\n",
    "    \n",
    "    data_set = data_sets[d]\n",
    "    \n",
    "    filename = os.path.join(save_dir, data_splits[d]+'.tfrecords')\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for index in range(data_set.images.shape[0]):\n",
    "        image = data_set.images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[data_set.images.shape[1]])),\n",
    "            'width': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[data_set.images.shape[2]])),\n",
    "            'depth': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[data_set.images.shape[3]])),\n",
    "            'label': tf.train.Feature(int64_list=tf.train.Int64List(\n",
    "                value=[int(data_set.labels[index])])),\n",
    "            'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image]))\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Read #####\n",
    "# tells string_input_producer() to produce each filename\n",
    "# string num_epochs times.\n",
    "num_epochs = 10\n",
    "\n",
    "filename = os.path.join(save_dir, \"train.tfrecords\")\n",
    "\n",
    "'''\n",
    "simply creates a QueueRunner behind the scenes, outputting \n",
    "filename strings to a queue for our input pipeline. This \n",
    "filename queue will be shared among multiple threads\n",
    "'''\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    [filename], num_epochs=num_epochs)\n",
    "\n",
    "'''\n",
    "Next, we read files from this queue using TFRecordReader() , which takes a queue of\n",
    "filenames and dequeues filename by filename off the filename_queue . Inter‐\n",
    "nally, TFRecordReader() uses the state of the graph to keep track of the location of\n",
    "the TFRecord being read, as it loads “chunk after chunk” of input data from the disk:\n",
    "'''\n",
    "reader = tf.TFRecordReader()\n",
    "\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={ 'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "              'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "\n",
    "image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "image.set_shape([784])\n",
    "\n",
    "\n",
    "image = tf.cast(image, tf.float32) * (1./255) - 0.5\n",
    "\n",
    "label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "\n",
    "# shuffle the example + batch\n",
    "\n",
    "'''\n",
    "shuffle the image instances and collect them into\n",
    "batch_size batches with tf.train.shuffle_batch() , which internally uses a Random\n",
    "ShuffleQueue and accumulates examples until it contains batch_size +\n",
    "min_after_dequeue elements:\n",
    "\n",
    "The mini-batches that are returned by shuffle_batch() are the\n",
    "result of a dequeue_many() call on the RandomShuffleQueue that is created internally.\n",
    "'''\n",
    "images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "    [image, label], batch_size=128, \n",
    "    capacity=2000, \n",
    "    min_after_dequeue=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(128), Dimension(784)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We define our simple softmax classification model as follows:\n",
    "W = tf.get_variable(\"W\", [28*28,10])\n",
    "y_pred = tf.matmul(images_batch, W)\n",
    "\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=y_pred, labels=label_batch)\n",
    "\n",
    "loss_mean = tf.reduce_mean(loss)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "init = tf.local_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally, we create threads that enqueue data to queues by calling\n",
    "tf.train.start_queue_runners() . Unlike other calls, this one is not symbolic and\n",
    "actually creates the threads (and thus needs to be done after initialization):\n",
    "'''\n",
    "\n",
    "##### coordinator ####\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany, stopped daemon 140654027745024)>,\n",
       " <Thread(QueueRunnerThread-input_producer-close_on_stop, started daemon 140654019352320)>,\n",
       " <Thread(QueueRunnerThread-input_producer_1-input_producer_1/input_producer_1_EnqueueMany, stopped daemon 140654010959616)>,\n",
       " <Thread(QueueRunnerThread-input_producer_1-close_on_stop, started daemon 140654002566912)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140653994174208)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-close_on_stop, started daemon 140653985781504)>,\n",
       " <Thread(QueueRunnerThread-input_producer_2-input_producer_2/input_producer_2_EnqueueMany, stopped daemon 140653977388800)>,\n",
       " <Thread(QueueRunnerThread-input_producer_2-close_on_stop, started daemon 140653968996096)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch_1/random_shuffle_queue-shuffle_batch_1/random_shuffle_queue_enqueue, started daemon 140653960603392)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch_1/random_shuffle_queue-close_on_stop, started daemon 140653952210688)>,\n",
       " <Thread(QueueRunnerThread-input_producer_3-input_producer_3/input_producer_3_EnqueueMany, stopped daemon 140653870708480)>,\n",
       " <Thread(QueueRunnerThread-input_producer_3-close_on_stop, started daemon 140653862315776)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch_2/random_shuffle_queue-shuffle_batch_2/random_shuffle_queue_enqueue, started daemon 140653853923072)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch_2/random_shuffle_queue-close_on_stop, started daemon 140653845530368)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "[0.38185358]\n",
      "1000\n",
      "[0.37215865]\n",
      "1500\n",
      "[0.33973002]\n",
      "2000\n",
      "[0.21747291]\n",
      "2500\n",
      "[0.48966697]\n",
      "3000\n",
      "[0.21363324]\n",
      "3500\n",
      "[0.33369952]\n",
      "4000\n",
      "[0.41267276]\n",
      "4500\n",
      "[0.24831854]\n",
      "Done training for 10 epochsm 4601 steps.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Having everything in place, we are now ready to run the multithreaded process, from\n",
    "reading and pre-processing batches into a queue to training a model. It’s important to\n",
    "note that we do not use the familiar feed_dict argument anymore—this avoids data\n",
    "copies and offers speedups, as discussed earlier in this chapter:\n",
    "'''\n",
    "\n",
    "try:\n",
    "    step = 0\n",
    "    while not coord.should_stop():\n",
    "        step += 1\n",
    "        sess.run([train_op])\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            loss_mean_val = sess.run([loss_mean])\n",
    "            print(step)\n",
    "            print(loss_mean_val)\n",
    "            \n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training for %d epochs, %d steps.' % (num_epochs, step))\n",
    "    \n",
    "finally:\n",
    "    # when done, ask the treads to stop.\n",
    "    coord.request_stop()\n",
    "    \n",
    "## wait for threads to finish\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We train until a tf.errors.OutOfRangeError error is thrown, indicating that queues are empty and we are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# example -- get image, label\n",
    "img1, lbel1 = sess.run([image,label])\n",
    "\n",
    "# example -- get random batch\n",
    "images, labels = sess.run([images_batch, labels_batch])\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
